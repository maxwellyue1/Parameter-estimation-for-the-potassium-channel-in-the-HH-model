{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e62e60b-f3fe-4134-a141-5afb594d10ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import sys  # Import the sys module\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "sys.path.append('..')\n",
    "from dataset_reader import Traces_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "754cf261-6249-4b93-b35b-cb29f6b7a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n"
     ]
    }
   ],
   "source": [
    "def params_2(hidden_size_list): \n",
    "    params = 0\n",
    "    for layer in range(len(hidden_size_list)+1):\n",
    "        if layer == 0:\n",
    "            params += 321*hidden_size_list[layer] + hidden_size_list[layer]\n",
    "        elif layer == len(hidden_size_list):\n",
    "            params += hidden_size_list[layer-1]*7+7\n",
    "        else: \n",
    "            params += hidden_size_list[layer]*hidden_size_list[layer]+hidden_size_list[layer]\n",
    "            \n",
    "    return params\n",
    "\n",
    "total_train_samples = 1800000\n",
    "params_ub = 1900000 // 9\n",
    "params_lb = 1900000 // 11\n",
    "\n",
    "\n",
    "layers = np.arange(3, 7)\n",
    "units = [32,64,128,256,512]\n",
    "\n",
    "valid_architecture = []\n",
    "for layer in layers:\n",
    "    # print(layer)\n",
    "    combinations = list(itertools.product(units, repeat=layer))\n",
    "    for comb in combinations:\n",
    "        if params_2(comb) <= params_ub and params_2(comb) >= params_lb:\n",
    "            valid_architecture.append(comb)\n",
    "print(len(valid_architecture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "863f9d8e-a319-421d-b53e-3391ac3007c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211111, 172727)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_ub, params_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b50adc04-c53b-42a2-86e4-a48d1666ed23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 256, 256),\n",
       " (512, 32, 128),\n",
       " (512, 64, 64),\n",
       " (512, 64, 128),\n",
       " (512, 128, 32),\n",
       " (512, 128, 64),\n",
       " (512, 128, 128),\n",
       " (32, 256, 256, 256),\n",
       " (128, 32, 256, 256),\n",
       " (128, 64, 256, 256),\n",
       " (128, 128, 256, 256),\n",
       " (128, 256, 32, 256),\n",
       " (128, 256, 64, 256),\n",
       " (128, 256, 128, 256),\n",
       " (128, 256, 256, 32),\n",
       " (128, 256, 256, 64),\n",
       " (128, 256, 256, 128),\n",
       " (256, 128, 128, 256),\n",
       " (256, 128, 256, 128),\n",
       " (256, 256, 128, 128),\n",
       " (512, 32, 32, 128),\n",
       " (512, 32, 64, 64),\n",
       " (512, 32, 64, 128),\n",
       " (512, 32, 128, 32),\n",
       " (512, 32, 128, 64),\n",
       " (512, 32, 128, 128),\n",
       " (512, 64, 32, 64),\n",
       " (512, 64, 32, 128),\n",
       " (512, 64, 64, 32),\n",
       " (512, 64, 64, 64),\n",
       " (512, 64, 64, 128),\n",
       " (512, 64, 128, 32),\n",
       " (512, 64, 128, 64),\n",
       " (512, 64, 128, 128),\n",
       " (512, 128, 32, 32),\n",
       " (512, 128, 32, 64),\n",
       " (512, 128, 32, 128),\n",
       " (512, 128, 64, 32),\n",
       " (512, 128, 64, 64),\n",
       " (512, 128, 64, 128),\n",
       " (512, 128, 128, 32),\n",
       " (512, 128, 128, 64),\n",
       " (32, 32, 256, 256, 256),\n",
       " (32, 128, 128, 256, 256),\n",
       " (32, 128, 256, 128, 256),\n",
       " (32, 128, 256, 256, 128),\n",
       " (32, 256, 32, 256, 256),\n",
       " (32, 256, 128, 128, 256),\n",
       " (32, 256, 128, 256, 128),\n",
       " (32, 256, 256, 32, 256),\n",
       " (32, 256, 256, 128, 128),\n",
       " (32, 256, 256, 256, 32),\n",
       " (64, 64, 128, 256, 256),\n",
       " (64, 64, 256, 128, 256),\n",
       " (64, 64, 256, 256, 128),\n",
       " (64, 128, 64, 256, 256),\n",
       " (64, 128, 128, 256, 256),\n",
       " (64, 128, 256, 64, 256),\n",
       " (64, 128, 256, 128, 256),\n",
       " (64, 128, 256, 256, 64),\n",
       " (64, 128, 256, 256, 128),\n",
       " (64, 256, 64, 128, 256),\n",
       " (64, 256, 64, 256, 128),\n",
       " (64, 256, 128, 64, 256),\n",
       " (64, 256, 128, 128, 256),\n",
       " (64, 256, 128, 256, 64),\n",
       " (64, 256, 128, 256, 128),\n",
       " (64, 256, 256, 64, 128),\n",
       " (64, 256, 256, 128, 64),\n",
       " (64, 256, 256, 128, 128),\n",
       " (128, 32, 32, 256, 256),\n",
       " (128, 32, 64, 256, 256),\n",
       " (128, 32, 128, 256, 256),\n",
       " (128, 32, 256, 32, 256),\n",
       " (128, 32, 256, 64, 256),\n",
       " (128, 32, 256, 128, 256),\n",
       " (128, 32, 256, 256, 32),\n",
       " (128, 32, 256, 256, 64),\n",
       " (128, 32, 256, 256, 128),\n",
       " (128, 64, 32, 256, 256),\n",
       " (128, 64, 64, 256, 256),\n",
       " (128, 64, 128, 256, 256),\n",
       " (128, 64, 256, 32, 256),\n",
       " (128, 64, 256, 64, 256),\n",
       " (128, 64, 256, 128, 256),\n",
       " (128, 64, 256, 256, 32),\n",
       " (128, 64, 256, 256, 64),\n",
       " (128, 64, 256, 256, 128),\n",
       " (128, 128, 32, 256, 256),\n",
       " (128, 128, 64, 256, 256),\n",
       " (128, 128, 128, 256, 256),\n",
       " (128, 128, 256, 32, 256),\n",
       " (128, 128, 256, 64, 256),\n",
       " (128, 128, 256, 128, 256),\n",
       " (128, 128, 256, 256, 32),\n",
       " (128, 128, 256, 256, 64),\n",
       " (128, 128, 256, 256, 128),\n",
       " (128, 256, 32, 32, 256),\n",
       " (128, 256, 32, 64, 256),\n",
       " (128, 256, 32, 128, 256),\n",
       " (128, 256, 32, 256, 32),\n",
       " (128, 256, 32, 256, 64),\n",
       " (128, 256, 32, 256, 128),\n",
       " (128, 256, 64, 32, 256),\n",
       " (128, 256, 64, 64, 256),\n",
       " (128, 256, 64, 128, 256),\n",
       " (128, 256, 64, 256, 32),\n",
       " (128, 256, 64, 256, 64),\n",
       " (128, 256, 64, 256, 128),\n",
       " (128, 256, 128, 32, 256),\n",
       " (128, 256, 128, 64, 256),\n",
       " (128, 256, 128, 128, 256),\n",
       " (128, 256, 128, 256, 32),\n",
       " (128, 256, 128, 256, 64),\n",
       " (128, 256, 128, 256, 128),\n",
       " (128, 256, 256, 32, 32),\n",
       " (128, 256, 256, 32, 64),\n",
       " (128, 256, 256, 32, 128),\n",
       " (128, 256, 256, 64, 32),\n",
       " (128, 256, 256, 64, 64),\n",
       " (128, 256, 256, 64, 128),\n",
       " (128, 256, 256, 128, 32),\n",
       " (128, 256, 256, 128, 64),\n",
       " (128, 256, 256, 128, 128),\n",
       " (256, 32, 128, 128, 256),\n",
       " (256, 32, 128, 256, 128),\n",
       " (256, 32, 256, 128, 128),\n",
       " (256, 64, 64, 128, 256),\n",
       " (256, 64, 64, 256, 128),\n",
       " (256, 64, 128, 64, 256),\n",
       " (256, 64, 128, 128, 256),\n",
       " (256, 64, 128, 256, 64),\n",
       " (256, 64, 128, 256, 128),\n",
       " (256, 64, 256, 64, 128),\n",
       " (256, 64, 256, 128, 64),\n",
       " (256, 64, 256, 128, 128),\n",
       " (256, 128, 32, 128, 256),\n",
       " (256, 128, 32, 256, 128),\n",
       " (256, 128, 64, 64, 256),\n",
       " (256, 128, 64, 128, 256),\n",
       " (256, 128, 64, 256, 64),\n",
       " (256, 128, 64, 256, 128),\n",
       " (256, 128, 128, 32, 256),\n",
       " (256, 128, 128, 64, 256),\n",
       " (256, 128, 128, 128, 256),\n",
       " (256, 128, 128, 256, 32),\n",
       " (256, 128, 128, 256, 64),\n",
       " (256, 128, 128, 256, 128),\n",
       " (256, 128, 256, 32, 128),\n",
       " (256, 128, 256, 64, 64),\n",
       " (256, 128, 256, 64, 128),\n",
       " (256, 128, 256, 128, 32),\n",
       " (256, 128, 256, 128, 64),\n",
       " (256, 128, 256, 128, 128),\n",
       " (256, 256, 32, 128, 128),\n",
       " (256, 256, 64, 64, 128),\n",
       " (256, 256, 64, 128, 64),\n",
       " (256, 256, 64, 128, 128),\n",
       " (256, 256, 128, 32, 128),\n",
       " (256, 256, 128, 64, 64),\n",
       " (256, 256, 128, 64, 128),\n",
       " (256, 256, 128, 128, 32),\n",
       " (256, 256, 128, 128, 64),\n",
       " (256, 256, 128, 128, 128),\n",
       " (512, 32, 32, 32, 128),\n",
       " (512, 32, 32, 64, 64),\n",
       " (512, 32, 32, 64, 128),\n",
       " (512, 32, 32, 128, 32),\n",
       " (512, 32, 32, 128, 64),\n",
       " (512, 32, 32, 128, 128),\n",
       " (512, 32, 64, 32, 64),\n",
       " (512, 32, 64, 32, 128),\n",
       " (512, 32, 64, 64, 32),\n",
       " (512, 32, 64, 64, 64),\n",
       " (512, 32, 64, 64, 128),\n",
       " (512, 32, 64, 128, 32),\n",
       " (512, 32, 64, 128, 64),\n",
       " (512, 32, 64, 128, 128),\n",
       " (512, 32, 128, 32, 32),\n",
       " (512, 32, 128, 32, 64),\n",
       " (512, 32, 128, 32, 128),\n",
       " (512, 32, 128, 64, 32),\n",
       " (512, 32, 128, 64, 64),\n",
       " (512, 32, 128, 64, 128),\n",
       " (512, 32, 128, 128, 32),\n",
       " (512, 32, 128, 128, 64),\n",
       " (512, 64, 32, 32, 64),\n",
       " (512, 64, 32, 32, 128),\n",
       " (512, 64, 32, 64, 32),\n",
       " (512, 64, 32, 64, 64),\n",
       " (512, 64, 32, 64, 128),\n",
       " (512, 64, 32, 128, 32),\n",
       " (512, 64, 32, 128, 64),\n",
       " (512, 64, 32, 128, 128),\n",
       " (512, 64, 64, 32, 32),\n",
       " (512, 64, 64, 32, 64),\n",
       " (512, 64, 64, 32, 128),\n",
       " (512, 64, 64, 64, 32),\n",
       " (512, 64, 64, 64, 64),\n",
       " (512, 64, 64, 64, 128),\n",
       " (512, 64, 64, 128, 32),\n",
       " (512, 64, 64, 128, 64),\n",
       " (512, 64, 64, 128, 128),\n",
       " (512, 64, 128, 32, 32),\n",
       " (512, 64, 128, 32, 64),\n",
       " (512, 64, 128, 32, 128),\n",
       " (512, 64, 128, 64, 32),\n",
       " (512, 64, 128, 64, 64),\n",
       " (512, 64, 128, 64, 128),\n",
       " (512, 64, 128, 128, 32),\n",
       " (512, 64, 128, 128, 64),\n",
       " (512, 128, 32, 32, 32),\n",
       " (512, 128, 32, 32, 64),\n",
       " (512, 128, 32, 32, 128),\n",
       " (512, 128, 32, 64, 32),\n",
       " (512, 128, 32, 64, 64),\n",
       " (512, 128, 32, 64, 128),\n",
       " (512, 128, 32, 128, 32),\n",
       " (512, 128, 32, 128, 64),\n",
       " (512, 128, 64, 32, 32),\n",
       " (512, 128, 64, 32, 64),\n",
       " (512, 128, 64, 32, 128),\n",
       " (512, 128, 64, 64, 32),\n",
       " (512, 128, 64, 64, 64),\n",
       " (512, 128, 64, 64, 128),\n",
       " (512, 128, 64, 128, 32),\n",
       " (512, 128, 64, 128, 64),\n",
       " (512, 128, 128, 32, 32),\n",
       " (512, 128, 128, 32, 64),\n",
       " (512, 128, 128, 64, 32),\n",
       " (512, 128, 128, 64, 64),\n",
       " (32, 32, 128, 128, 256, 256),\n",
       " (32, 32, 128, 256, 128, 256),\n",
       " (32, 32, 128, 256, 256, 128),\n",
       " (32, 32, 256, 128, 128, 256),\n",
       " (32, 32, 256, 128, 256, 128),\n",
       " (32, 32, 256, 256, 128, 128),\n",
       " (32, 32, 256, 256, 256, 32),\n",
       " (32, 64, 128, 128, 256, 256),\n",
       " (32, 64, 128, 256, 128, 256),\n",
       " (32, 64, 128, 256, 256, 128),\n",
       " (32, 64, 256, 128, 128, 256),\n",
       " (32, 64, 256, 128, 256, 128),\n",
       " (32, 64, 256, 256, 128, 128),\n",
       " (32, 128, 32, 128, 256, 256),\n",
       " (32, 128, 32, 256, 128, 256),\n",
       " (32, 128, 32, 256, 256, 128),\n",
       " (32, 128, 64, 128, 256, 256),\n",
       " (32, 128, 64, 256, 128, 256),\n",
       " (32, 128, 64, 256, 256, 128),\n",
       " (32, 128, 128, 32, 256, 256),\n",
       " (32, 128, 128, 64, 256, 256),\n",
       " (32, 128, 128, 128, 256, 256),\n",
       " (32, 128, 128, 256, 32, 256),\n",
       " (32, 128, 128, 256, 64, 256),\n",
       " (32, 128, 128, 256, 128, 256),\n",
       " (32, 128, 128, 256, 256, 32),\n",
       " (32, 128, 128, 256, 256, 64),\n",
       " (32, 128, 128, 256, 256, 128),\n",
       " (32, 128, 256, 32, 128, 256),\n",
       " (32, 128, 256, 32, 256, 128),\n",
       " (32, 128, 256, 64, 128, 256),\n",
       " (32, 128, 256, 64, 256, 128),\n",
       " (32, 128, 256, 128, 32, 256),\n",
       " (32, 128, 256, 128, 64, 256),\n",
       " (32, 128, 256, 128, 128, 256),\n",
       " (32, 128, 256, 128, 256, 32),\n",
       " (32, 128, 256, 128, 256, 64),\n",
       " (32, 128, 256, 128, 256, 128),\n",
       " (32, 128, 256, 256, 32, 128),\n",
       " (32, 128, 256, 256, 64, 128),\n",
       " (32, 128, 256, 256, 128, 32),\n",
       " (32, 128, 256, 256, 128, 64),\n",
       " (32, 128, 256, 256, 128, 128),\n",
       " (32, 256, 32, 128, 128, 256),\n",
       " (32, 256, 32, 128, 256, 128),\n",
       " (32, 256, 32, 256, 128, 128),\n",
       " (32, 256, 32, 256, 256, 32),\n",
       " (32, 256, 64, 128, 128, 256),\n",
       " (32, 256, 64, 128, 256, 128),\n",
       " (32, 256, 64, 256, 128, 128),\n",
       " (32, 256, 128, 32, 128, 256),\n",
       " (32, 256, 128, 32, 256, 128),\n",
       " (32, 256, 128, 64, 128, 256),\n",
       " (32, 256, 128, 64, 256, 128),\n",
       " (32, 256, 128, 128, 32, 256),\n",
       " (32, 256, 128, 128, 64, 256),\n",
       " (32, 256, 128, 128, 128, 256),\n",
       " (32, 256, 128, 128, 256, 32),\n",
       " (32, 256, 128, 128, 256, 64),\n",
       " (32, 256, 128, 128, 256, 128),\n",
       " (32, 256, 128, 256, 32, 128),\n",
       " (32, 256, 128, 256, 64, 128),\n",
       " (32, 256, 128, 256, 128, 32),\n",
       " (32, 256, 128, 256, 128, 64),\n",
       " (32, 256, 128, 256, 128, 128),\n",
       " (32, 256, 256, 32, 128, 128),\n",
       " (32, 256, 256, 32, 256, 32),\n",
       " (32, 256, 256, 64, 128, 128),\n",
       " (32, 256, 256, 128, 32, 128),\n",
       " (32, 256, 256, 128, 64, 128),\n",
       " (32, 256, 256, 128, 128, 32),\n",
       " (32, 256, 256, 128, 128, 64),\n",
       " (32, 256, 256, 128, 128, 128),\n",
       " (32, 256, 256, 256, 32, 32),\n",
       " (64, 32, 64, 128, 256, 256),\n",
       " (64, 32, 64, 256, 128, 256),\n",
       " (64, 32, 64, 256, 256, 128),\n",
       " (64, 32, 128, 64, 256, 256),\n",
       " (64, 32, 128, 128, 256, 256),\n",
       " (64, 32, 128, 256, 64, 256),\n",
       " (64, 32, 128, 256, 128, 256),\n",
       " (64, 32, 128, 256, 256, 64),\n",
       " (64, 32, 128, 256, 256, 128),\n",
       " (64, 32, 256, 64, 128, 256),\n",
       " (64, 32, 256, 64, 256, 128),\n",
       " (64, 32, 256, 128, 64, 256),\n",
       " (64, 32, 256, 128, 128, 256),\n",
       " (64, 32, 256, 128, 256, 64),\n",
       " (64, 32, 256, 128, 256, 128),\n",
       " (64, 32, 256, 256, 64, 128),\n",
       " (64, 32, 256, 256, 128, 64),\n",
       " (64, 32, 256, 256, 128, 128),\n",
       " (64, 64, 32, 128, 256, 256),\n",
       " (64, 64, 32, 256, 128, 256),\n",
       " (64, 64, 32, 256, 256, 128),\n",
       " (64, 64, 64, 128, 256, 256),\n",
       " (64, 64, 64, 256, 128, 256),\n",
       " (64, 64, 64, 256, 256, 128),\n",
       " (64, 64, 128, 32, 256, 256),\n",
       " (64, 64, 128, 64, 256, 256),\n",
       " (64, 64, 128, 128, 256, 256),\n",
       " (64, 64, 128, 256, 32, 256),\n",
       " (64, 64, 128, 256, 64, 256),\n",
       " (64, 64, 128, 256, 128, 256),\n",
       " (64, 64, 128, 256, 256, 32),\n",
       " (64, 64, 128, 256, 256, 64),\n",
       " (64, 64, 128, 256, 256, 128),\n",
       " (64, 64, 256, 32, 128, 256),\n",
       " (64, 64, 256, 32, 256, 128),\n",
       " (64, 64, 256, 64, 128, 256),\n",
       " (64, 64, 256, 64, 256, 128),\n",
       " (64, 64, 256, 128, 32, 256),\n",
       " (64, 64, 256, 128, 64, 256),\n",
       " (64, 64, 256, 128, 128, 256),\n",
       " (64, 64, 256, 128, 256, 32),\n",
       " (64, 64, 256, 128, 256, 64),\n",
       " (64, 64, 256, 128, 256, 128),\n",
       " (64, 64, 256, 256, 32, 128),\n",
       " (64, 64, 256, 256, 64, 128),\n",
       " (64, 64, 256, 256, 128, 32),\n",
       " (64, 64, 256, 256, 128, 64),\n",
       " (64, 64, 256, 256, 128, 128),\n",
       " (64, 128, 32, 64, 256, 256),\n",
       " (64, 128, 32, 128, 256, 256),\n",
       " (64, 128, 32, 256, 64, 256),\n",
       " (64, 128, 32, 256, 128, 256),\n",
       " (64, 128, 32, 256, 256, 64),\n",
       " (64, 128, 32, 256, 256, 128),\n",
       " (64, 128, 64, 32, 256, 256),\n",
       " (64, 128, 64, 64, 256, 256),\n",
       " (64, 128, 64, 128, 256, 256),\n",
       " (64, 128, 64, 256, 32, 256),\n",
       " (64, 128, 64, 256, 64, 256),\n",
       " (64, 128, 64, 256, 128, 256),\n",
       " (64, 128, 64, 256, 256, 32),\n",
       " (64, 128, 64, 256, 256, 64),\n",
       " (64, 128, 64, 256, 256, 128),\n",
       " (64, 128, 128, 32, 256, 256),\n",
       " (64, 128, 128, 64, 256, 256),\n",
       " (64, 128, 128, 128, 256, 256),\n",
       " (64, 128, 128, 256, 32, 256),\n",
       " (64, 128, 128, 256, 64, 256),\n",
       " (64, 128, 128, 256, 128, 256),\n",
       " (64, 128, 128, 256, 256, 32),\n",
       " (64, 128, 128, 256, 256, 64),\n",
       " (64, 128, 128, 256, 256, 128),\n",
       " (64, 128, 256, 32, 64, 256),\n",
       " (64, 128, 256, 32, 128, 256),\n",
       " (64, 128, 256, 32, 256, 64),\n",
       " (64, 128, 256, 32, 256, 128),\n",
       " (64, 128, 256, 64, 32, 256),\n",
       " (64, 128, 256, 64, 64, 256),\n",
       " (64, 128, 256, 64, 128, 256),\n",
       " (64, 128, 256, 64, 256, 32),\n",
       " (64, 128, 256, 64, 256, 64),\n",
       " (64, 128, 256, 64, 256, 128),\n",
       " (64, 128, 256, 128, 32, 256),\n",
       " (64, 128, 256, 128, 64, 256),\n",
       " (64, 128, 256, 128, 128, 256),\n",
       " (64, 128, 256, 128, 256, 32),\n",
       " (64, 128, 256, 128, 256, 64),\n",
       " (64, 128, 256, 128, 256, 128),\n",
       " (64, 128, 256, 256, 32, 64),\n",
       " (64, 128, 256, 256, 32, 128),\n",
       " (64, 128, 256, 256, 64, 32),\n",
       " (64, 128, 256, 256, 64, 64),\n",
       " (64, 128, 256, 256, 64, 128),\n",
       " (64, 128, 256, 256, 128, 32),\n",
       " (64, 128, 256, 256, 128, 64),\n",
       " (64, 128, 256, 256, 128, 128),\n",
       " (64, 256, 32, 64, 128, 256),\n",
       " (64, 256, 32, 64, 256, 128),\n",
       " (64, 256, 32, 128, 64, 256),\n",
       " (64, 256, 32, 128, 128, 256),\n",
       " (64, 256, 32, 128, 256, 64),\n",
       " (64, 256, 32, 128, 256, 128),\n",
       " (64, 256, 32, 256, 64, 128),\n",
       " (64, 256, 32, 256, 128, 64),\n",
       " (64, 256, 32, 256, 128, 128),\n",
       " (64, 256, 64, 32, 128, 256),\n",
       " (64, 256, 64, 32, 256, 128),\n",
       " (64, 256, 64, 64, 128, 256),\n",
       " (64, 256, 64, 64, 256, 128),\n",
       " (64, 256, 64, 128, 32, 256),\n",
       " (64, 256, 64, 128, 64, 256),\n",
       " (64, 256, 64, 128, 128, 256),\n",
       " (64, 256, 64, 128, 256, 32),\n",
       " (64, 256, 64, 128, 256, 64),\n",
       " (64, 256, 64, 128, 256, 128),\n",
       " (64, 256, 64, 256, 32, 128),\n",
       " (64, 256, 64, 256, 64, 128),\n",
       " (64, 256, 64, 256, 128, 32),\n",
       " (64, 256, 64, 256, 128, 64),\n",
       " (64, 256, 64, 256, 128, 128),\n",
       " (64, 256, 128, 32, 64, 256),\n",
       " (64, 256, 128, 32, 128, 256),\n",
       " (64, 256, 128, 32, 256, 64),\n",
       " (64, 256, 128, 32, 256, 128),\n",
       " (64, 256, 128, 64, 32, 256),\n",
       " (64, 256, 128, 64, 64, 256),\n",
       " (64, 256, 128, 64, 128, 256),\n",
       " (64, 256, 128, 64, 256, 32),\n",
       " (64, 256, 128, 64, 256, 64),\n",
       " (64, 256, 128, 64, 256, 128),\n",
       " (64, 256, 128, 128, 32, 256),\n",
       " (64, 256, 128, 128, 64, 256),\n",
       " (64, 256, 128, 128, 128, 256),\n",
       " (64, 256, 128, 128, 256, 32),\n",
       " (64, 256, 128, 128, 256, 64),\n",
       " (64, 256, 128, 128, 256, 128),\n",
       " (64, 256, 128, 256, 32, 64),\n",
       " (64, 256, 128, 256, 32, 128),\n",
       " (64, 256, 128, 256, 64, 32),\n",
       " (64, 256, 128, 256, 64, 64),\n",
       " (64, 256, 128, 256, 64, 128),\n",
       " (64, 256, 128, 256, 128, 32),\n",
       " (64, 256, 128, 256, 128, 64),\n",
       " (64, 256, 128, 256, 128, 128),\n",
       " (64, 256, 256, 32, 64, 128),\n",
       " (64, 256, 256, 32, 128, 64),\n",
       " (64, 256, 256, 32, 128, 128),\n",
       " (64, 256, 256, 64, 32, 128),\n",
       " (64, 256, 256, 64, 64, 128),\n",
       " (64, 256, 256, 64, 128, 32),\n",
       " (64, 256, 256, 64, 128, 64),\n",
       " (64, 256, 256, 64, 128, 128),\n",
       " (64, 256, 256, 128, 32, 64),\n",
       " (64, 256, 256, 128, 32, 128),\n",
       " (64, 256, 256, 128, 64, 32),\n",
       " (64, 256, 256, 128, 64, 64),\n",
       " (64, 256, 256, 128, 64, 128),\n",
       " (64, 256, 256, 128, 128, 32),\n",
       " (64, 256, 256, 128, 128, 64),\n",
       " (64, 256, 256, 128, 128, 128),\n",
       " (128, 32, 32, 32, 256, 256),\n",
       " (128, 32, 32, 64, 256, 256),\n",
       " (128, 32, 32, 128, 256, 256),\n",
       " (128, 32, 32, 256, 32, 256),\n",
       " (128, 32, 32, 256, 64, 256),\n",
       " (128, 32, 32, 256, 128, 256),\n",
       " (128, 32, 32, 256, 256, 32),\n",
       " (128, 32, 32, 256, 256, 64),\n",
       " (128, 32, 32, 256, 256, 128),\n",
       " (128, 32, 64, 32, 256, 256),\n",
       " (128, 32, 64, 64, 256, 256),\n",
       " (128, 32, 64, 128, 256, 256),\n",
       " (128, 32, 64, 256, 32, 256),\n",
       " (128, 32, 64, 256, 64, 256),\n",
       " (128, 32, 64, 256, 128, 256),\n",
       " (128, 32, 64, 256, 256, 32),\n",
       " (128, 32, 64, 256, 256, 64),\n",
       " (128, 32, 64, 256, 256, 128),\n",
       " (128, 32, 128, 32, 256, 256),\n",
       " (128, 32, 128, 64, 256, 256),\n",
       " (128, 32, 128, 128, 256, 256),\n",
       " (128, 32, 128, 256, 32, 256),\n",
       " (128, 32, 128, 256, 64, 256),\n",
       " (128, 32, 128, 256, 128, 256),\n",
       " (128, 32, 128, 256, 256, 32),\n",
       " (128, 32, 128, 256, 256, 64),\n",
       " (128, 32, 128, 256, 256, 128),\n",
       " (128, 32, 256, 32, 32, 256),\n",
       " (128, 32, 256, 32, 64, 256),\n",
       " (128, 32, 256, 32, 128, 256),\n",
       " (128, 32, 256, 32, 256, 32),\n",
       " (128, 32, 256, 32, 256, 64),\n",
       " (128, 32, 256, 32, 256, 128),\n",
       " (128, 32, 256, 64, 32, 256),\n",
       " (128, 32, 256, 64, 64, 256),\n",
       " (128, 32, 256, 64, 128, 256),\n",
       " (128, 32, 256, 64, 256, 32),\n",
       " (128, 32, 256, 64, 256, 64),\n",
       " (128, 32, 256, 64, 256, 128),\n",
       " (128, 32, 256, 128, 32, 256),\n",
       " (128, 32, 256, 128, 64, 256),\n",
       " (128, 32, 256, 128, 128, 256),\n",
       " (128, 32, 256, 128, 256, 32),\n",
       " (128, 32, 256, 128, 256, 64),\n",
       " (128, 32, 256, 128, 256, 128),\n",
       " (128, 32, 256, 256, 32, 32),\n",
       " (128, 32, 256, 256, 32, 64),\n",
       " (128, 32, 256, 256, 32, 128),\n",
       " (128, 32, 256, 256, 64, 32),\n",
       " (128, 32, 256, 256, 64, 64),\n",
       " (128, 32, 256, 256, 64, 128),\n",
       " (128, 32, 256, 256, 128, 32),\n",
       " (128, 32, 256, 256, 128, 64),\n",
       " (128, 32, 256, 256, 128, 128),\n",
       " (128, 64, 32, 32, 256, 256),\n",
       " (128, 64, 32, 64, 256, 256),\n",
       " (128, 64, 32, 128, 256, 256),\n",
       " (128, 64, 32, 256, 32, 256),\n",
       " (128, 64, 32, 256, 64, 256),\n",
       " (128, 64, 32, 256, 128, 256),\n",
       " (128, 64, 32, 256, 256, 32),\n",
       " (128, 64, 32, 256, 256, 64),\n",
       " (128, 64, 32, 256, 256, 128),\n",
       " (128, 64, 64, 32, 256, 256),\n",
       " (128, 64, 64, 64, 256, 256),\n",
       " (128, 64, 64, 128, 256, 256),\n",
       " (128, 64, 64, 256, 32, 256),\n",
       " (128, 64, 64, 256, 64, 256),\n",
       " (128, 64, 64, 256, 128, 256),\n",
       " (128, 64, 64, 256, 256, 32),\n",
       " (128, 64, 64, 256, 256, 64),\n",
       " (128, 64, 64, 256, 256, 128),\n",
       " (128, 64, 128, 32, 256, 256),\n",
       " (128, 64, 128, 64, 256, 256),\n",
       " (128, 64, 128, 256, 32, 256),\n",
       " (128, 64, 128, 256, 64, 256),\n",
       " (128, 64, 128, 256, 256, 32),\n",
       " (128, 64, 128, 256, 256, 64),\n",
       " (128, 64, 128, 256, 256, 128),\n",
       " (128, 64, 256, 32, 32, 256),\n",
       " (128, 64, 256, 32, 64, 256),\n",
       " (128, 64, 256, 32, 128, 256),\n",
       " (128, 64, 256, 32, 256, 32),\n",
       " (128, 64, 256, 32, 256, 64),\n",
       " (128, 64, 256, 32, 256, 128),\n",
       " (128, 64, 256, 64, 32, 256),\n",
       " (128, 64, 256, 64, 64, 256),\n",
       " (128, 64, 256, 64, 128, 256),\n",
       " (128, 64, 256, 64, 256, 32),\n",
       " (128, 64, 256, 64, 256, 64),\n",
       " (128, 64, 256, 64, 256, 128),\n",
       " (128, 64, 256, 128, 32, 256),\n",
       " (128, 64, 256, 128, 64, 256),\n",
       " (128, 64, 256, 128, 256, 32),\n",
       " (128, 64, 256, 128, 256, 64),\n",
       " (128, 64, 256, 128, 256, 128),\n",
       " (128, 64, 256, 256, 32, 32),\n",
       " (128, 64, 256, 256, 32, 64),\n",
       " (128, 64, 256, 256, 32, 128),\n",
       " (128, 64, 256, 256, 64, 32),\n",
       " (128, 64, 256, 256, 64, 64),\n",
       " (128, 64, 256, 256, 64, 128),\n",
       " (128, 64, 256, 256, 128, 32),\n",
       " (128, 64, 256, 256, 128, 64),\n",
       " (128, 64, 256, 256, 128, 128),\n",
       " (128, 128, 32, 32, 256, 256),\n",
       " (128, 128, 32, 64, 256, 256),\n",
       " (128, 128, 32, 128, 256, 256),\n",
       " (128, 128, 32, 256, 32, 256),\n",
       " (128, 128, 32, 256, 64, 256),\n",
       " (128, 128, 32, 256, 128, 256),\n",
       " (128, 128, 32, 256, 256, 32),\n",
       " (128, 128, 32, 256, 256, 64),\n",
       " (128, 128, 32, 256, 256, 128),\n",
       " (128, 128, 64, 32, 256, 256),\n",
       " (128, 128, 64, 64, 256, 256),\n",
       " (128, 128, 64, 256, 32, 256),\n",
       " (128, 128, 64, 256, 64, 256),\n",
       " (128, 128, 64, 256, 256, 32),\n",
       " (128, 128, 64, 256, 256, 64),\n",
       " (128, 128, 64, 256, 256, 128),\n",
       " (128, 128, 128, 32, 256, 256),\n",
       " (128, 128, 128, 128, 128, 256),\n",
       " (128, 128, 128, 128, 256, 128),\n",
       " (128, 128, 128, 256, 32, 256),\n",
       " (128, 128, 128, 256, 128, 128),\n",
       " (128, 128, 128, 256, 256, 32),\n",
       " (128, 128, 128, 256, 256, 64),\n",
       " (128, 128, 256, 32, 32, 256),\n",
       " (128, 128, 256, 32, 64, 256),\n",
       " (128, 128, 256, 32, 128, 256),\n",
       " (128, 128, 256, 32, 256, 32),\n",
       " (128, 128, 256, 32, 256, 64),\n",
       " (128, 128, 256, 32, 256, 128),\n",
       " (128, 128, 256, 64, 32, 256),\n",
       " (128, 128, 256, 64, 64, 256),\n",
       " (128, 128, 256, 64, 256, 32),\n",
       " (128, 128, 256, 64, 256, 64),\n",
       " (128, 128, 256, 64, 256, 128),\n",
       " (128, 128, 256, 128, 32, 256),\n",
       " (128, 128, 256, 128, 128, 128),\n",
       " (128, 128, 256, 128, 256, 32),\n",
       " (128, 128, 256, 128, 256, 64),\n",
       " (128, 128, 256, 256, 32, 32),\n",
       " (128, 128, 256, 256, 32, 64),\n",
       " (128, 128, 256, 256, 32, 128),\n",
       " (128, 128, 256, 256, 64, 32),\n",
       " (128, 128, 256, 256, 64, 64),\n",
       " (128, 128, 256, 256, 64, 128),\n",
       " (128, 128, 256, 256, 128, 32),\n",
       " (128, 128, 256, 256, 128, 64),\n",
       " (128, 256, 32, 32, 32, 256),\n",
       " (128, 256, 32, 32, 64, 256),\n",
       " (128, 256, 32, 32, 128, 256),\n",
       " (128, 256, 32, 32, 256, 32),\n",
       " (128, 256, 32, 32, 256, 64),\n",
       " (128, 256, 32, 32, 256, 128),\n",
       " (128, 256, 32, 64, 32, 256),\n",
       " (128, 256, 32, 64, 64, 256),\n",
       " (128, 256, 32, 64, 128, 256),\n",
       " (128, 256, 32, 64, 256, 32),\n",
       " (128, 256, 32, 64, 256, 64),\n",
       " (128, 256, 32, 64, 256, 128),\n",
       " (128, 256, 32, 128, 32, 256),\n",
       " (128, 256, 32, 128, 64, 256),\n",
       " (128, 256, 32, 128, 128, 256),\n",
       " (128, 256, 32, 128, 256, 32),\n",
       " (128, 256, 32, 128, 256, 64),\n",
       " (128, 256, 32, 128, 256, 128),\n",
       " (128, 256, 32, 256, 32, 32),\n",
       " (128, 256, 32, 256, 32, 64),\n",
       " (128, 256, 32, 256, 32, 128),\n",
       " (128, 256, 32, 256, 64, 32),\n",
       " (128, 256, 32, 256, 64, 64),\n",
       " (128, 256, 32, 256, 64, 128),\n",
       " (128, 256, 32, 256, 128, 32),\n",
       " (128, 256, 32, 256, 128, 64),\n",
       " (128, 256, 32, 256, 128, 128),\n",
       " (128, 256, 64, 32, 32, 256),\n",
       " (128, 256, 64, 32, 64, 256),\n",
       " (128, 256, 64, 32, 128, 256),\n",
       " (128, 256, 64, 32, 256, 32),\n",
       " (128, 256, 64, 32, 256, 64),\n",
       " (128, 256, 64, 32, 256, 128),\n",
       " (128, 256, 64, 64, 32, 256),\n",
       " (128, 256, 64, 64, 64, 256),\n",
       " (128, 256, 64, 64, 128, 256),\n",
       " (128, 256, 64, 64, 256, 32),\n",
       " (128, 256, 64, 64, 256, 64),\n",
       " (128, 256, 64, 64, 256, 128),\n",
       " (128, 256, 64, 128, 32, 256),\n",
       " (128, 256, 64, 128, 64, 256),\n",
       " (128, 256, 64, 128, 256, 32),\n",
       " (128, 256, 64, 128, 256, 64),\n",
       " (128, 256, 64, 128, 256, 128),\n",
       " (128, 256, 64, 256, 32, 32),\n",
       " (128, 256, 64, 256, 32, 64),\n",
       " (128, 256, 64, 256, 32, 128),\n",
       " (128, 256, 64, 256, 64, 32),\n",
       " (128, 256, 64, 256, 64, 64),\n",
       " (128, 256, 64, 256, 64, 128),\n",
       " (128, 256, 64, 256, 128, 32),\n",
       " (128, 256, 64, 256, 128, 64),\n",
       " (128, 256, 64, 256, 128, 128),\n",
       " (128, 256, 128, 32, 32, 256),\n",
       " (128, 256, 128, 32, 64, 256),\n",
       " (128, 256, 128, 32, 128, 256),\n",
       " (128, 256, 128, 32, 256, 32),\n",
       " (128, 256, 128, 32, 256, 64),\n",
       " (128, 256, 128, 32, 256, 128),\n",
       " (128, 256, 128, 64, 32, 256),\n",
       " (128, 256, 128, 64, 64, 256),\n",
       " (128, 256, 128, 64, 256, 32),\n",
       " (128, 256, 128, 64, 256, 64),\n",
       " (128, 256, 128, 64, 256, 128),\n",
       " (128, 256, 128, 128, 32, 256),\n",
       " (128, 256, 128, 128, 128, 128),\n",
       " (128, 256, 128, 128, 256, 32),\n",
       " (128, 256, 128, 128, 256, 64),\n",
       " (128, 256, 128, 256, 32, 32),\n",
       " (128, 256, 128, 256, 32, 64),\n",
       " (128, 256, 128, 256, 32, 128),\n",
       " (128, 256, 128, 256, 64, 32),\n",
       " (128, 256, 128, 256, 64, 64),\n",
       " (128, 256, 128, 256, 64, 128),\n",
       " (128, 256, 128, 256, 128, 32),\n",
       " (128, 256, 128, 256, 128, 64),\n",
       " (128, 256, 256, 32, 32, 32),\n",
       " (128, 256, 256, 32, 32, 64),\n",
       " (128, 256, 256, 32, 32, 128),\n",
       " (128, 256, 256, 32, 64, 32),\n",
       " (128, 256, 256, 32, 64, 64),\n",
       " (128, 256, 256, 32, 64, 128),\n",
       " (128, 256, 256, 32, 128, 32),\n",
       " (128, 256, 256, 32, 128, 64),\n",
       " (128, 256, 256, 32, 128, 128),\n",
       " (128, 256, 256, 64, 32, 32),\n",
       " (128, 256, 256, 64, 32, 64),\n",
       " (128, 256, 256, 64, 32, 128),\n",
       " (128, 256, 256, 64, 64, 32),\n",
       " (128, 256, 256, 64, 64, 64),\n",
       " (128, 256, 256, 64, 64, 128),\n",
       " (128, 256, 256, 64, 128, 32),\n",
       " (128, 256, 256, 64, 128, 64),\n",
       " (128, 256, 256, 64, 128, 128),\n",
       " (128, 256, 256, 128, 32, 32),\n",
       " (128, 256, 256, 128, 32, 64),\n",
       " (128, 256, 256, 128, 32, 128),\n",
       " (128, 256, 256, 128, 64, 32),\n",
       " (128, 256, 256, 128, 64, 64),\n",
       " (128, 256, 256, 128, 64, 128),\n",
       " (128, 256, 256, 128, 128, 32),\n",
       " (128, 256, 256, 128, 128, 64),\n",
       " (256, 32, 32, 64, 128, 256),\n",
       " (256, 32, 32, 128, 64, 256),\n",
       " (256, 32, 32, 128, 128, 256),\n",
       " (256, 32, 32, 128, 256, 128),\n",
       " (256, 32, 32, 256, 128, 128),\n",
       " (256, 32, 64, 32, 128, 256),\n",
       " (256, 32, 64, 64, 128, 256),\n",
       " (256, 32, 64, 64, 256, 128),\n",
       " (256, 32, 64, 128, 32, 256),\n",
       " (256, 32, 64, 128, 64, 256),\n",
       " (256, 32, 64, 128, 128, 256),\n",
       " (256, 32, 64, 128, 256, 64),\n",
       " (256, 32, 64, 128, 256, 128),\n",
       " (256, 32, 64, 256, 64, 128),\n",
       " (256, 32, 64, 256, 128, 64),\n",
       " (256, 32, 64, 256, 128, 128),\n",
       " (256, 32, 128, 32, 64, 256),\n",
       " (256, 32, 128, 32, 128, 256),\n",
       " (256, 32, 128, 32, 256, 128),\n",
       " (256, 32, 128, 64, 32, 256),\n",
       " (256, 32, 128, 64, 64, 256),\n",
       " (256, 32, 128, 64, 128, 256),\n",
       " (256, 32, 128, 64, 256, 64),\n",
       " (256, 32, 128, 64, 256, 128),\n",
       " (256, 32, 128, 128, 32, 256),\n",
       " (256, 32, 128, 128, 64, 256),\n",
       " (256, 32, 128, 128, 128, 256),\n",
       " (256, 32, 128, 128, 256, 32),\n",
       " (256, 32, 128, 128, 256, 64),\n",
       " (256, 32, 128, 128, 256, 128),\n",
       " (256, 32, 128, 256, 32, 128),\n",
       " (256, 32, 128, 256, 64, 64),\n",
       " (256, 32, 128, 256, 64, 128),\n",
       " (256, 32, 128, 256, 128, 32),\n",
       " (256, 32, 128, 256, 128, 64),\n",
       " (256, 32, 128, 256, 128, 128),\n",
       " (256, 32, 256, 32, 128, 128),\n",
       " (256, 32, 256, 64, 64, 128),\n",
       " (256, 32, 256, 64, 128, 64),\n",
       " (256, 32, 256, 64, 128, 128),\n",
       " (256, 32, 256, 128, 32, 128),\n",
       " (256, 32, 256, 128, 64, 64),\n",
       " (256, 32, 256, 128, 64, 128),\n",
       " (256, 32, 256, 128, 128, 32),\n",
       " (256, 32, 256, 128, 128, 64),\n",
       " (256, 32, 256, 128, 128, 128),\n",
       " (256, 64, 32, 32, 128, 256),\n",
       " (256, 64, 32, 64, 128, 256),\n",
       " (256, 64, 32, 64, 256, 128),\n",
       " (256, 64, 32, 128, 32, 256),\n",
       " (256, 64, 32, 128, 64, 256),\n",
       " (256, 64, 32, 128, 128, 256),\n",
       " (256, 64, 32, 128, 256, 64),\n",
       " (256, 64, 32, 128, 256, 128),\n",
       " (256, 64, 32, 256, 64, 128),\n",
       " (256, 64, 32, 256, 128, 64),\n",
       " (256, 64, 32, 256, 128, 128),\n",
       " (256, 64, 64, 32, 128, 256),\n",
       " (256, 64, 64, 32, 256, 128),\n",
       " (256, 64, 64, 64, 128, 256),\n",
       " (256, 64, 64, 64, 256, 128),\n",
       " (256, 64, 64, 128, 32, 256),\n",
       " (256, 64, 64, 128, 64, 256),\n",
       " (256, 64, 64, 128, 128, 256),\n",
       " (256, 64, 64, 128, 256, 32),\n",
       " (256, 64, 64, 128, 256, 64),\n",
       " (256, 64, 64, 128, 256, 128),\n",
       " (256, 64, 64, 256, 32, 128),\n",
       " (256, 64, 64, 256, 64, 128),\n",
       " (256, 64, 64, 256, 128, 32),\n",
       " (256, 64, 64, 256, 128, 64),\n",
       " (256, 64, 64, 256, 128, 128),\n",
       " (256, 64, 128, 32, 32, 256),\n",
       " (256, 64, 128, 32, 64, 256),\n",
       " (256, 64, 128, 32, 128, 256),\n",
       " (256, 64, 128, 32, 256, 64),\n",
       " (256, 64, 128, 32, 256, 128),\n",
       " (256, 64, 128, 64, 32, 256),\n",
       " (256, 64, 128, 64, 64, 256),\n",
       " (256, 64, 128, 64, 128, 256),\n",
       " (256, 64, 128, 64, 256, 32),\n",
       " (256, 64, 128, 64, 256, 64),\n",
       " (256, 64, 128, 64, 256, 128),\n",
       " (256, 64, 128, 128, 32, 256),\n",
       " (256, 64, 128, 128, 64, 256),\n",
       " (256, 64, 128, 128, 128, 256),\n",
       " (256, 64, 128, 128, 256, 32),\n",
       " (256, 64, 128, 128, 256, 64),\n",
       " (256, 64, 128, 128, 256, 128),\n",
       " (256, 64, 128, 256, 32, 64),\n",
       " (256, 64, 128, 256, 32, 128),\n",
       " (256, 64, 128, 256, 64, 32),\n",
       " (256, 64, 128, 256, 64, 64),\n",
       " (256, 64, 128, 256, 64, 128),\n",
       " (256, 64, 128, 256, 128, 32),\n",
       " (256, 64, 128, 256, 128, 64),\n",
       " (256, 64, 128, 256, 128, 128),\n",
       " (256, 64, 256, 32, 64, 128),\n",
       " (256, 64, 256, 32, 128, 64),\n",
       " (256, 64, 256, 32, 128, 128),\n",
       " (256, 64, 256, 64, 32, 128),\n",
       " (256, 64, 256, 64, 64, 128),\n",
       " (256, 64, 256, 64, 128, 32),\n",
       " (256, 64, 256, 64, 128, 64),\n",
       " (256, 64, 256, 64, 128, 128),\n",
       " (256, 64, 256, 128, 32, 64),\n",
       " (256, 64, 256, 128, 32, 128),\n",
       " (256, 64, 256, 128, 64, 32),\n",
       " (256, 64, 256, 128, 64, 64),\n",
       " (256, 64, 256, 128, 64, 128),\n",
       " (256, 64, 256, 128, 128, 32),\n",
       " (256, 64, 256, 128, 128, 64),\n",
       " (256, 64, 256, 128, 128, 128),\n",
       " (256, 128, 32, 32, 64, 256),\n",
       " (256, 128, 32, 32, 128, 256),\n",
       " (256, 128, 32, 32, 256, 128),\n",
       " (256, 128, 32, 64, 32, 256),\n",
       " (256, 128, 32, 64, 64, 256),\n",
       " (256, 128, 32, 64, 128, 256),\n",
       " (256, 128, 32, 64, 256, 64),\n",
       " (256, 128, 32, 64, 256, 128),\n",
       " (256, 128, 32, 128, 32, 256),\n",
       " (256, 128, 32, 128, 64, 256),\n",
       " (256, 128, 32, 128, 128, 256),\n",
       " (256, 128, 32, 128, 256, 32),\n",
       " (256, 128, 32, 128, 256, 64),\n",
       " (256, 128, 32, 128, 256, 128),\n",
       " (256, 128, 32, 256, 32, 128),\n",
       " (256, 128, 32, 256, 64, 64),\n",
       " (256, 128, 32, 256, 64, 128),\n",
       " (256, 128, 32, 256, 128, 32),\n",
       " (256, 128, 32, 256, 128, 64),\n",
       " (256, 128, 32, 256, 128, 128),\n",
       " (256, 128, 64, 32, 32, 256),\n",
       " (256, 128, 64, 32, 64, 256),\n",
       " (256, 128, 64, 32, 128, 256),\n",
       " (256, 128, 64, 32, 256, 64),\n",
       " (256, 128, 64, 32, 256, 128),\n",
       " (256, 128, 64, 64, 32, 256),\n",
       " (256, 128, 64, 64, 64, 256),\n",
       " (256, 128, 64, 64, 128, 256),\n",
       " (256, 128, 64, 64, 256, 32),\n",
       " (256, 128, 64, 64, 256, 64),\n",
       " (256, 128, 64, 64, 256, 128),\n",
       " (256, 128, 64, 128, 32, 256),\n",
       " (256, 128, 64, 128, 64, 256),\n",
       " (256, 128, 64, 128, 128, 256),\n",
       " (256, 128, 64, 128, 256, 32),\n",
       " (256, 128, 64, 128, 256, 64),\n",
       " (256, 128, 64, 128, 256, 128),\n",
       " (256, 128, 64, 256, 32, 64),\n",
       " (256, 128, 64, 256, 32, 128),\n",
       " (256, 128, 64, 256, 64, 32),\n",
       " (256, 128, 64, 256, 64, 64),\n",
       " (256, 128, 64, 256, 64, 128),\n",
       " (256, 128, 64, 256, 128, 32),\n",
       " (256, 128, 64, 256, 128, 64),\n",
       " (256, 128, 64, 256, 128, 128),\n",
       " (256, 128, 128, 32, 32, 256),\n",
       " (256, 128, 128, 32, 64, 256),\n",
       " (256, 128, 128, 32, 128, 256),\n",
       " (256, 128, 128, 32, 256, 32),\n",
       " (256, 128, 128, 32, 256, 64),\n",
       " (256, 128, 128, 32, 256, 128),\n",
       " (256, 128, 128, 64, 32, 256),\n",
       " (256, 128, 128, 64, 64, 256),\n",
       " (256, 128, 128, 64, 128, 256),\n",
       " (256, 128, 128, 64, 256, 32),\n",
       " (256, 128, 128, 64, 256, 64),\n",
       " (256, 128, 128, 64, 256, 128),\n",
       " (256, 128, 128, 128, 32, 256),\n",
       " (256, 128, 128, 128, 64, 256),\n",
       " (256, 128, 128, 128, 256, 32),\n",
       " (256, 128, 128, 128, 256, 64),\n",
       " (256, 128, 128, 256, 32, 32),\n",
       " (256, 128, 128, 256, 32, 64),\n",
       " (256, 128, 128, 256, 32, 128),\n",
       " (256, 128, 128, 256, 64, 32),\n",
       " (256, 128, 128, 256, 64, 64),\n",
       " (256, 128, 128, 256, 64, 128),\n",
       " (256, 128, 128, 256, 128, 32),\n",
       " (256, 128, 128, 256, 128, 64),\n",
       " (256, 128, 256, 32, 32, 128),\n",
       " (256, 128, 256, 32, 64, 64),\n",
       " (256, 128, 256, 32, 64, 128),\n",
       " (256, 128, 256, 32, 128, 32),\n",
       " (256, 128, 256, 32, 128, 64),\n",
       " (256, 128, 256, 32, 128, 128),\n",
       " (256, 128, 256, 64, 32, 64),\n",
       " (256, 128, 256, 64, 32, 128),\n",
       " (256, 128, 256, 64, 64, 32),\n",
       " (256, 128, 256, 64, 64, 64),\n",
       " (256, 128, 256, 64, 64, 128),\n",
       " (256, 128, 256, 64, 128, 32),\n",
       " (256, 128, 256, 64, 128, 64),\n",
       " (256, 128, 256, 64, 128, 128),\n",
       " (256, 128, 256, 128, 32, 32),\n",
       " (256, 128, 256, 128, 32, 64),\n",
       " (256, 128, 256, 128, 32, 128),\n",
       " (256, 128, 256, 128, 64, 32),\n",
       " (256, 128, 256, 128, 64, 64),\n",
       " (256, 128, 256, 128, 64, 128),\n",
       " (256, 128, 256, 128, 128, 32),\n",
       " (256, 128, 256, 128, 128, 64),\n",
       " (256, 256, 32, 32, 128, 128),\n",
       " (256, 256, 32, 64, 64, 128),\n",
       " (256, 256, 32, 64, 128, 64),\n",
       " (256, 256, 32, 64, 128, 128),\n",
       " (256, 256, 32, 128, 32, 128),\n",
       " (256, 256, 32, 128, 64, 64),\n",
       " (256, 256, 32, 128, 64, 128),\n",
       " (256, 256, 32, 128, 128, 32),\n",
       " (256, 256, 32, 128, 128, 64),\n",
       " (256, 256, 32, 128, 128, 128),\n",
       " (256, 256, 64, 32, 64, 128),\n",
       " (256, 256, 64, 32, 128, 64),\n",
       " (256, 256, 64, 32, 128, 128),\n",
       " (256, 256, 64, 64, 32, 128),\n",
       " (256, 256, 64, 64, 64, 128),\n",
       " (256, 256, 64, 64, 128, 32),\n",
       " (256, 256, 64, 64, 128, 64),\n",
       " (256, 256, 64, 64, 128, 128),\n",
       " (256, 256, 64, 128, 32, 64),\n",
       " (256, 256, 64, 128, 32, 128),\n",
       " (256, 256, 64, 128, 64, 32),\n",
       " (256, 256, 64, 128, 64, 64),\n",
       " (256, 256, 64, 128, 64, 128),\n",
       " (256, 256, 64, 128, 128, 32),\n",
       " (256, 256, 64, 128, 128, 64),\n",
       " (256, 256, 64, 128, 128, 128),\n",
       " (256, 256, 128, 32, 32, 128),\n",
       " (256, 256, 128, 32, 64, 64),\n",
       " (256, 256, 128, 32, 64, 128),\n",
       " (256, 256, 128, 32, 128, 32),\n",
       " (256, 256, 128, 32, 128, 64),\n",
       " (256, 256, 128, 32, 128, 128),\n",
       " (256, 256, 128, 64, 32, 64),\n",
       " (256, 256, 128, 64, 32, 128),\n",
       " (256, 256, 128, 64, 64, 32),\n",
       " (256, 256, 128, 64, 64, 64),\n",
       " (256, 256, 128, 64, 64, 128),\n",
       " (256, 256, 128, 64, 128, 32),\n",
       " (256, 256, 128, 64, 128, 64),\n",
       " (256, 256, 128, 64, 128, 128),\n",
       " (256, 256, 128, 128, 32, 32),\n",
       " (256, 256, 128, 128, 32, 64),\n",
       " (256, 256, 128, 128, 32, 128),\n",
       " (256, 256, 128, 128, 64, 32),\n",
       " (256, 256, 128, 128, 64, 64),\n",
       " (256, 256, 128, 128, 64, 128),\n",
       " (256, 256, 128, 128, 128, 32),\n",
       " (256, 256, 128, 128, 128, 64),\n",
       " (512, 32, 32, 32, 32, 64),\n",
       " (512, 32, 32, 32, 32, 128),\n",
       " (512, 32, 32, 32, 64, 32),\n",
       " (512, 32, 32, 32, 64, 64),\n",
       " (512, 32, 32, 32, 64, 128),\n",
       " (512, 32, 32, 32, 128, 32),\n",
       " (512, 32, 32, 32, 128, 64),\n",
       " (512, 32, 32, 32, 128, 128),\n",
       " (512, 32, 32, 64, 32, 32),\n",
       " (512, 32, 32, 64, 32, 64),\n",
       " (512, 32, 32, 64, 32, 128),\n",
       " (512, 32, 32, 64, 64, 32),\n",
       " (512, 32, 32, 64, 64, 64),\n",
       " (512, 32, 32, 64, 64, 128),\n",
       " (512, 32, 32, 64, 128, 32),\n",
       " (512, 32, 32, 64, 128, 64),\n",
       " (512, 32, 32, 64, 128, 128),\n",
       " (512, 32, 32, 128, 32, 32),\n",
       " (512, 32, 32, 128, 32, 64),\n",
       " (512, 32, 32, 128, 32, 128),\n",
       " (512, 32, 32, 128, 64, 32),\n",
       " (512, 32, 32, 128, 64, 64),\n",
       " (512, 32, 32, 128, 64, 128),\n",
       " (512, 32, 32, 128, 128, 32),\n",
       " (512, 32, 32, 128, 128, 64),\n",
       " (512, 32, 64, 32, 32, 32),\n",
       " (512, 32, 64, 32, 32, 64),\n",
       " (512, 32, 64, 32, 32, 128),\n",
       " (512, 32, 64, 32, 64, 32),\n",
       " (512, 32, 64, 32, 64, 64),\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d041a7a4-537e-45a7-bdff-7b047a7eb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making training reproducible\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "history_dict['seed'] = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb3d65b9-c662-468c-b5a5-5736af3cb9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000000, 321])\n"
     ]
    }
   ],
   "source": [
    "# load and process dataset \n",
    "dataset = Traces_Dataset('../dataset2mil.csv')\n",
    "dataset.split_dataset(0.9, 0.1, 0)\n",
    "dataset.clean_features()\n",
    "dataset.find_mean_std()\n",
    "dataset.normalize()\n",
    "print(dataset.inputs.shape)\n",
    "# history_dict['normalize_mean'] = dataset.train_mean.tolist()\n",
    "# history_dict['normalize_std'] = dataset.train_std.tolist()\n",
    "# history_dict['dataset'] = (dataset.inputs.shape[0], dataset.inputs.shape[1])\n",
    "\n",
    "# initialize train, val, test set\n",
    "X_train = dataset[dataset.train_set.indices][0]\n",
    "Y_train = dataset[dataset.train_set.indices][1]\n",
    "\n",
    "X_val = dataset[dataset.val_set.indices][0]\n",
    "Y_val = dataset[dataset.val_set.indices][1]\n",
    "\n",
    "X_test = dataset[dataset.test_set.indices][0]\n",
    "Y_test = dataset[dataset.test_set.indices][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26661cf1-6118-4852-ae4b-b68b29722178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, hidden_sizes, input_size = 321, output_size = 7):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_hidden_layers = len(hidden_sizes)\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define the input layer\n",
    "        self.input_layer = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.SiLU(),  # SILU activation function\n",
    "                nn.BatchNorm1d(hidden_sizes[0]))\n",
    "\n",
    "        # Define the hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[i], hidden_sizes[i+1]),\n",
    "                nn.SiLU(),  # SILU activation function\n",
    "                nn.BatchNorm1d(hidden_sizes[i+1])\n",
    "            )\n",
    "            for i in range(len(hidden_sizes) - 1)\n",
    "        ])\n",
    "\n",
    "        # Define the output layer\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        x = self.input_layer(x)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                # Apply Xavier initialization to linear layers\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                # Initialize biases, for example, with zeros\n",
    "                if layer.bias is not None:\n",
    "                    init.constant_(layer.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f478548e-0fec-4295-a254-88bae2bed92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "n_epochs = 10   # number of epochs to run\n",
    "batch_size = 1024  # size of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a7f2b47-ea96-495d-b231-5b46f59dd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataloader \n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4a78db1-12ba-4bcd-a5a8-7d3a0f9f9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training history to a csv file\n",
    "def log_data_to_csv(row_data, file_path = 'experiment_logbook_architecture_10.csv'): \n",
    "    '''\n",
    "    row_data is a dictionary of the row_data we want to store\n",
    "    '''\n",
    "    # Check if the file exists\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "\n",
    "    with open(file_path, mode='a' if file_exists else 'w', newline='') as csv_file:\n",
    "        # Create a CSV writer object\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # If the file is newly created, write the header row\n",
    "        if not file_exists:\n",
    "            header_row = row_data.keys() if isinstance(row_data, dict) else row_data\n",
    "            csv_writer.writerow(header_row)\n",
    "\n",
    "        # Write the data row\n",
    "        if isinstance(row_data, dict):\n",
    "            csv_writer.writerow(row_data.values())\n",
    "        else:\n",
    "            csv_writer.writerow(row_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a94ea-46a3-4c26-a963-b298a56544d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "(128, 256, 256)\n",
      "1: train-437.689812995468, val-11.240462113399895\n",
      "2: train-7.466146794059849, val-7.530413048607962\n",
      "3: train-5.559840645535136, val-8.42097289708196\n",
      "4: train-4.664150880872186, val-9.499806863921028\n",
      "5: train-4.094331381670851, val-6.803266719895966\n",
      "6: train-3.8023388544447188, val-4.543630445490078\n",
      "7: train-3.434773721792592, val-5.062230207482163\n",
      "8: train-3.1800797143622606, val-7.174579374644221\n",
      "9: train-3.0186345217849073, val-20.984430921321014\n",
      "10: train-2.9141244171558114, val-2.7307219383667927\n",
      "achitecture: (128, 256, 256)\n",
      "\n",
      "best_epoch: 10\n",
      "\n",
      "best_val: 2.7307219383667927\n",
      "\n",
      "best_train: 2.9141244171558114\n",
      "\n",
      "training_loss: [437.689812995468, 7.466146794059849, 5.559840645535136, 4.664150880872186, 4.094331381670851, 3.8023388544447188, 3.434773721792592, 3.1800797143622606, 3.0186345217849073, 2.9141244171558114]\n",
      "\n",
      "validation_loss: [11.240462113399895, 7.530413048607962, 8.42097289708196, 9.499806863921028, 6.803266719895966, 4.543630445490078, 5.062230207482163, 7.174579374644221, 20.984430921321014, 2.7307219383667927]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 32, 128)\n",
      "1: train-606.0784266616162, val-12.98148868035297\n",
      "2: train-9.990981508576152, val-9.888363609508593\n",
      "3: train-7.867950591346645, val-11.93826581507313\n",
      "4: train-6.553872365322265, val-7.906143640985294\n",
      "5: train-5.781479681311207, val-5.115636874218376\n",
      "6: train-5.063876090331831, val-7.404770843836726\n",
      "7: train-4.679957015251272, val-21.79726927621024\n",
      "8: train-4.259131366211128, val-7.283982165005742\n",
      "9: train-3.9924205243248445, val-5.042913709368024\n",
      "10: train-3.82433212373037, val-10.29037010426424\n",
      "achitecture: (512, 32, 128)\n",
      "\n",
      "best_epoch: 9\n",
      "\n",
      "best_val: 5.042913709368024\n",
      "\n",
      "best_train: 3.9924205243248445\n",
      "\n",
      "training_loss: [606.0784266616162, 9.990981508576152, 7.867950591346645, 6.553872365322265, 5.781479681311207, 5.063876090331831, 4.679957015251272, 4.259131366211128, 3.9924205243248445, 3.82433212373037]\n",
      "\n",
      "validation_loss: [12.98148868035297, 9.888363609508593, 11.93826581507313, 7.906143640985294, 5.115636874218376, 7.404770843836726, 21.79726927621024, 7.283982165005742, 5.042913709368024, 10.29037010426424]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 64, 64)\n",
      "1: train-844.2087916883049, val-13.871232572866946\n",
      "2: train-9.227345175574936, val-12.84695796577298\n",
      "3: train-7.050749344766072, val-5.64135362177479\n",
      "4: train-6.023166072246565, val-5.95930138412787\n",
      "5: train-5.3514071717875265, val-7.916889884033981\n",
      "6: train-4.869317045662048, val-4.363327918004017\n",
      "7: train-4.583803095779593, val-8.497891683967746\n",
      "8: train-4.319470902487415, val-10.963175700635325\n",
      "9: train-4.05046298533712, val-5.9508872445748775\n",
      "10: train-3.7897054373336463, val-5.454454144653009\n",
      "achitecture: (512, 64, 64)\n",
      "\n",
      "best_epoch: 6\n",
      "\n",
      "best_val: 4.363327918004017\n",
      "\n",
      "best_train: 4.869317045662048\n",
      "\n",
      "training_loss: [844.2087916883049, 9.227345175574936, 7.050749344766072, 6.023166072246565, 5.3514071717875265, 4.869317045662048, 4.583803095779593, 4.319470902487415, 4.05046298533712, 3.7897054373336463]\n",
      "\n",
      "validation_loss: [13.871232572866946, 12.84695796577298, 5.64135362177479, 5.95930138412787, 7.916889884033981, 4.363327918004017, 8.497891683967746, 10.963175700635325, 5.9508872445748775, 5.454454144653009]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 64, 128)\n",
      "1: train-604.0198517719091, val-10.898845088725187\n",
      "2: train-8.896833826114971, val-9.295314178174856\n",
      "3: train-6.827024720227759, val-15.715831333277176\n",
      "4: train-5.681965584098547, val-9.89777365022776\n",
      "5: train-5.04762950963399, val-6.602918525131381\n",
      "6: train-4.4986466295483165, val-5.963245126665855\n",
      "7: train-4.209428409125075, val-5.981088635872822\n",
      "8: train-3.8275478614475134, val-7.971340006711531\n",
      "9: train-3.6473577860679236, val-5.279166588977891\n",
      "10: train-3.4218538537095973, val-3.676784800023449\n",
      "achitecture: (512, 64, 128)\n",
      "\n",
      "best_epoch: 10\n",
      "\n",
      "best_val: 3.676784800023449\n",
      "\n",
      "best_train: 3.4218538537095973\n",
      "\n",
      "training_loss: [604.0198517719091, 8.896833826114971, 6.827024720227759, 5.681965584098547, 5.04762950963399, 4.4986466295483165, 4.209428409125075, 3.8275478614475134, 3.6473577860679236, 3.4218538537095973]\n",
      "\n",
      "validation_loss: [10.898845088725187, 9.295314178174856, 15.715831333277176, 9.89777365022776, 6.602918525131381, 5.963245126665855, 5.981088635872822, 7.971340006711531, 5.279166588977891, 3.676784800023449]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 128, 32)\n",
      "1: train-1183.022808148728, val-19.38079160573531\n",
      "2: train-10.004718693450043, val-7.403617019556006\n",
      "3: train-6.911536875302746, val-6.682859880583627\n",
      "4: train-5.848129771675266, val-6.428642630577087\n",
      "5: train-5.175420283593144, val-9.053448976302633\n",
      "6: train-4.709286588857605, val-9.636000871658325\n",
      "7: train-4.398969103451882, val-8.196809031525436\n",
      "8: train-4.111247316833514, val-5.188339892698794\n",
      "9: train-3.9490612035996544, val-4.814431969000369\n",
      "10: train-3.742435833564255, val-3.966711873910865\n",
      "achitecture: (512, 128, 32)\n",
      "\n",
      "best_epoch: 10\n",
      "\n",
      "best_val: 3.966711873910865\n",
      "\n",
      "best_train: 3.742435833564255\n",
      "\n",
      "training_loss: [1183.022808148728, 10.004718693450043, 6.911536875302746, 5.848129771675266, 5.175420283593144, 4.709286588857605, 4.398969103451882, 4.111247316833514, 3.9490612035996544, 3.742435833564255]\n",
      "\n",
      "validation_loss: [19.38079160573531, 7.403617019556006, 6.682859880583627, 6.428642630577087, 9.053448976302633, 9.636000871658325, 8.196809031525436, 5.188339892698794, 4.814431969000369, 3.966711873910865]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 128, 64)\n",
      "1: train-841.7719114534684, val-12.773925615816701\n",
      "2: train-8.56703998258632, val-7.523974255639679\n",
      "3: train-6.582698538034849, val-8.444672265831304\n",
      "4: train-5.480098843167666, val-13.552322275784551\n",
      "5: train-4.858788377053366, val-6.043302480055361\n",
      "6: train-4.424239807839551, val-11.615970022824346\n",
      "7: train-4.10586542942147, val-3.9679634850852343\n",
      "8: train-3.821493635541072, val-3.24308910540172\n",
      "9: train-3.5387787991145094, val-4.587231358703302\n",
      "10: train-3.412322364569524, val-10.694997057622793\n",
      "achitecture: (512, 128, 64)\n",
      "\n",
      "best_epoch: 8\n",
      "\n",
      "best_val: 3.24308910540172\n",
      "\n",
      "best_train: 3.821493635541072\n",
      "\n",
      "training_loss: [841.7719114534684, 8.56703998258632, 6.582698538034849, 5.480098843167666, 4.858788377053366, 4.424239807839551, 4.10586542942147, 3.821493635541072, 3.5387787991145094, 3.412322364569524]\n",
      "\n",
      "validation_loss: [12.773925615816701, 7.523974255639679, 8.444672265831304, 13.552322275784551, 6.043302480055361, 11.615970022824346, 3.9679634850852343, 3.24308910540172, 4.587231358703302, 10.694997057622793]\n",
      "\n",
      "Using device: cuda\n",
      "(512, 128, 128)\n",
      "1: train-602.5215540081432, val-10.444090254452764\n",
      "2: train-7.971626894465892, val-8.660563138066506\n",
      "3: train-6.148144230772068, val-4.712414996964591\n",
      "4: train-5.097895023765824, val-4.736639506962835\n",
      "5: train-4.4892176708399365, val-7.3008942993319765\n",
      "6: train-4.034735850642294, val-5.8659184781872495\n",
      "7: train-3.759769147844716, val-4.0744025038213145\n",
      "8: train-3.4806013663338584, val-6.59018363514725\n",
      "9: train-3.351248537449842, val-5.334801642262206\n",
      "10: train-3.1343875020166037, val-4.2097620112555365\n",
      "achitecture: (512, 128, 128)\n",
      "\n",
      "best_epoch: 7\n",
      "\n",
      "best_val: 4.0744025038213145\n",
      "\n",
      "best_train: 3.759769147844716\n",
      "\n",
      "training_loss: [602.5215540081432, 7.971626894465892, 6.148144230772068, 5.097895023765824, 4.4892176708399365, 4.034735850642294, 3.759769147844716, 3.4806013663338584, 3.351248537449842, 3.1343875020166037]\n",
      "\n",
      "validation_loss: [10.444090254452764, 8.660563138066506, 4.712414996964591, 4.736639506962835, 7.3008942993319765, 5.8659184781872495, 4.0744025038213145, 6.59018363514725, 5.334801642262206, 4.2097620112555365]\n",
      "\n",
      "Using device: cuda\n",
      "(32, 256, 256, 256)\n",
      "1: train-435.9536284857914, val-8.846202607057533\n",
      "2: train-7.165153653955297, val-6.758109022159966\n",
      "3: train-5.368362767162041, val-7.030167786442504\n",
      "4: train-4.4351828151188615, val-5.320540508445428\n",
      "5: train-4.042348767574601, val-10.810577567742795\n",
      "6: train-3.53342883307508, val-4.97303058663193\n",
      "7: train-3.272743252221499, val-6.642628331573642\n",
      "8: train-3.0199363611392736, val-20.77919181025758\n",
      "9: train-2.9153533265994813, val-6.464335205603619\n",
      "10: train-2.6995796839938637, val-8.202521324157715\n",
      "achitecture: (32, 256, 256, 256)\n",
      "\n",
      "best_epoch: 6\n",
      "\n",
      "best_val: 4.97303058663193\n",
      "\n",
      "best_train: 3.53342883307508\n",
      "\n",
      "training_loss: [435.9536284857914, 7.165153653955297, 5.368362767162041, 4.4351828151188615, 4.042348767574601, 3.53342883307508, 3.272743252221499, 3.0199363611392736, 2.9153533265994813, 2.6995796839938637]\n",
      "\n",
      "validation_loss: [8.846202607057533, 6.758109022159966, 7.030167786442504, 5.320540508445428, 10.810577567742795, 4.97303058663193, 6.642628331573642, 20.77919181025758, 6.464335205603619, 8.202521324157715]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 32, 256, 256)\n",
      "1: train-436.1743894567262, val-13.997410054109535\n",
      "2: train-7.731664924220149, val-8.592410175167785\n",
      "3: train-5.748088412859876, val-4.759956959558993\n",
      "4: train-4.700234992241018, val-6.674304217708354\n",
      "5: train-4.120242404449515, val-10.285614675405075\n",
      "6: train-3.7701506820826265, val-6.921404758278205\n",
      "7: train-3.483484587164869, val-7.147540272498618\n",
      "8: train-3.222115916468042, val-27.200695378439768\n",
      "9: train-3.079158137411523, val-6.398390076598343\n",
      "10: train-2.9218671993862104, val-9.982339941725439\n",
      "achitecture: (128, 32, 256, 256)\n",
      "\n",
      "best_epoch: 3\n",
      "\n",
      "best_val: 4.759956959558993\n",
      "\n",
      "best_train: 5.748088412859876\n",
      "\n",
      "training_loss: [436.1743894567262, 7.731664924220149, 5.748088412859876, 4.700234992241018, 4.120242404449515, 3.7701506820826265, 3.483484587164869, 3.222115916468042, 3.079158137411523, 2.9218671993862104]\n",
      "\n",
      "validation_loss: [13.997410054109535, 8.592410175167785, 4.759956959558993, 6.674304217708354, 10.285614675405075, 6.921404758278205, 7.147540272498618, 27.200695378439768, 6.398390076598343, 9.982339941725439]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 64, 256, 256)\n",
      "1: train-435.1022971091417, val-13.957941196402725\n",
      "2: train-7.236910444613338, val-6.553500207103029\n",
      "3: train-5.3214147154652895, val-14.130385374536319\n",
      "4: train-4.51980570016325, val-8.82328419296109\n",
      "5: train-3.817873402260269, val-4.859612417464354\n",
      "6: train-3.459849409953997, val-4.685733011790684\n",
      "7: train-3.3302180710099254, val-10.180088417870659\n",
      "8: train-2.950130677874178, val-8.605840305892789\n",
      "9: train-2.8981980794661415, val-14.05060965674264\n",
      "10: train-2.667714440239439, val-6.4804757833480835\n",
      "achitecture: (128, 64, 256, 256)\n",
      "\n",
      "best_epoch: 6\n",
      "\n",
      "best_val: 4.685733011790684\n",
      "\n",
      "best_train: 3.459849409953997\n",
      "\n",
      "training_loss: [435.1022971091417, 7.236910444613338, 5.3214147154652895, 4.51980570016325, 3.817873402260269, 3.459849409953997, 3.3302180710099254, 2.950130677874178, 2.8981980794661415, 2.667714440239439]\n",
      "\n",
      "validation_loss: [13.957941196402725, 6.553500207103029, 14.130385374536319, 8.82328419296109, 4.859612417464354, 4.685733011790684, 10.180088417870659, 8.605840305892789, 14.05060965674264, 6.4804757833480835]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 128, 256, 256)\n",
      "1: train-434.0024105249411, val-7.880559451726018\n",
      "2: train-6.22320746561773, val-8.925180644405131\n",
      "3: train-4.807039256253205, val-4.734461796527007\n",
      "4: train-4.05560923436396, val-9.384874796380801\n",
      "5: train-3.5938006068523696, val-9.844417294677424\n",
      "6: train-3.2171997621197748, val-8.435037347735191\n",
      "7: train-3.040308888251464, val-2.7704255568737888\n",
      "8: train-2.763549971431324, val-8.191771942742017\n",
      "9: train-2.5966706285433285, val-9.133335675512042\n",
      "10: train-2.4945549383098355, val-6.80220936025892\n",
      "achitecture: (128, 128, 256, 256)\n",
      "\n",
      "best_epoch: 7\n",
      "\n",
      "best_val: 2.7704255568737888\n",
      "\n",
      "best_train: 3.040308888251464\n",
      "\n",
      "training_loss: [434.0024105249411, 6.22320746561773, 4.807039256253205, 4.05560923436396, 3.5938006068523696, 3.2171997621197748, 3.040308888251464, 2.763549971431324, 2.5966706285433285, 2.4945549383098355]\n",
      "\n",
      "validation_loss: [7.880559451726018, 8.925180644405131, 4.734461796527007, 9.384874796380801, 9.844417294677424, 8.435037347735191, 2.7704255568737888, 8.191771942742017, 9.133335675512042, 6.80220936025892]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 256, 32, 256)\n",
      "1: train-437.2753955439089, val-7.895300376171968\n",
      "2: train-7.284610285015779, val-7.975670741528881\n",
      "3: train-5.646746606143261, val-6.389849093495583\n",
      "4: train-4.843533416928149, val-6.220558940147867\n",
      "5: train-4.222025871548094, val-6.377481922811391\n",
      "6: train-3.825039706810614, val-6.140711976557362\n",
      "7: train-3.4394189565526205, val-7.212990607534136\n",
      "8: train-3.238607386408948, val-6.313333382411879\n",
      "9: train-2.960608914308038, val-4.04078456941916\n",
      "10: train-2.8238624921566524, val-3.3337105914038054\n",
      "achitecture: (128, 256, 32, 256)\n",
      "\n",
      "best_epoch: 10\n",
      "\n",
      "best_val: 3.3337105914038054\n",
      "\n",
      "best_train: 2.8238624921566524\n",
      "\n",
      "training_loss: [437.2753955439089, 7.284610285015779, 5.646746606143261, 4.843533416928149, 4.222025871548094, 3.825039706810614, 3.4394189565526205, 3.238607386408948, 2.960608914308038, 2.8238624921566524]\n",
      "\n",
      "validation_loss: [7.895300376171968, 7.975670741528881, 6.389849093495583, 6.220558940147867, 6.377481922811391, 6.140711976557362, 7.212990607534136, 6.313333382411879, 4.04078456941916, 3.3337105914038054]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 256, 64, 256)\n",
      "1: train-435.90633011894965, val-13.616395249658702\n",
      "2: train-6.764568721881906, val-7.326433648868483\n",
      "3: train-5.135133874023055, val-13.368509501827006\n",
      "4: train-4.273288669032855, val-14.213766681904696\n",
      "5: train-3.793103679997658, val-7.384978087580934\n",
      "6: train-3.3626195900269336, val-3.1314153549622517\n",
      "7: train-3.1719459240347043, val-5.298070007440995\n",
      "8: train-2.8835001425802775, val-11.009512453663106\n",
      "9: train-2.6891847793288335, val-5.571846699228092\n",
      "10: train-2.5989517551911434, val-19.49768163719956\n",
      "achitecture: (128, 256, 64, 256)\n",
      "\n",
      "best_epoch: 6\n",
      "\n",
      "best_val: 3.1314153549622517\n",
      "\n",
      "best_train: 3.3626195900269336\n",
      "\n",
      "training_loss: [435.90633011894965, 6.764568721881906, 5.135133874023055, 4.273288669032855, 3.793103679997658, 3.3626195900269336, 3.1719459240347043, 2.8835001425802775, 2.6891847793288335, 2.5989517551911434]\n",
      "\n",
      "validation_loss: [13.616395249658702, 7.326433648868483, 13.368509501827006, 14.213766681904696, 7.384978087580934, 3.1314153549622517, 5.298070007440995, 11.009512453663106, 5.571846699228092, 19.49768163719956]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 256, 128, 256)\n",
      "1: train-434.2408864381506, val-11.5277696239705\n",
      "2: train-6.528102460846017, val-13.857805709449613\n",
      "3: train-4.992981165749221, val-14.252333115558235\n",
      "4: train-4.142133539447198, val-4.881325696195875\n",
      "5: train-3.639421368486103, val-6.648901474719145\n",
      "6: train-3.229708496553228, val-5.706638954123672\n",
      "7: train-3.0113959500949674, val-3.6985162009998245\n",
      "8: train-2.7894118348893047, val-8.625171240495176\n",
      "9: train-2.5715620006446276, val-11.998665799899976\n",
      "10: train-2.4758302428345362, val-6.275368544520164\n",
      "achitecture: (128, 256, 128, 256)\n",
      "\n",
      "best_epoch: 7\n",
      "\n",
      "best_val: 3.6985162009998245\n",
      "\n",
      "best_train: 3.0113959500949674\n",
      "\n",
      "training_loss: [434.2408864381506, 6.528102460846017, 4.992981165749221, 4.142133539447198, 3.639421368486103, 3.229708496553228, 3.0113959500949674, 2.7894118348893047, 2.5715620006446276, 2.4758302428345362]\n",
      "\n",
      "validation_loss: [11.5277696239705, 13.857805709449613, 14.252333115558235, 4.881325696195875, 6.648901474719145, 5.706638954123672, 3.6985162009998245, 8.625171240495176, 11.998665799899976, 6.275368544520164]\n",
      "\n",
      "Using device: cuda\n",
      "(128, 256, 256, 32)\n",
      "1: train-1188.2931765772241, val-28.903316312906693\n",
      "2: train-8.08367235872119, val-13.554358209882464\n"
     ]
    }
   ],
   "source": [
    "for achitecture in valid_architecture[:100]: \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Uncomment this line\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # initialize a dictionary of training history to store in a csv file\n",
    "    history_dict = {}\n",
    "    ###########################################################################\n",
    "    achitecture = achitecture\n",
    "    history_dict['achitecture'] = achitecture\n",
    "    print(achitecture)\n",
    "    ###########################################################################\n",
    "\n",
    "    model = FeedForwardNN(achitecture, dataset.inputs.shape[1], dataset.params.shape[1]).to(device)\n",
    "    model.initialize_weights()\n",
    "\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.MSELoss()  # mean square error\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    \n",
    "    # initialization train, val losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_validation_loss = float('inf')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0.0\n",
    "    \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = loss_fn(outputs, labels)  # Calculate the loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "            total_loss += loss.item()\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "    \n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        total_val_loss = 0.0\n",
    "    \n",
    "        with torch.no_grad():  # Disable gradient calculation during validation\n",
    "            # validation\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = loss_fn(val_outputs, val_labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "        # Average validation loss for the epoch\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "    \n",
    "        print(f'{epoch}: train-{avg_train_loss}, val-{avg_val_loss}')\n",
    "    \n",
    "        if avg_val_loss < best_validation_loss:\n",
    "            best_epoch = epoch\n",
    "            # model_path = checkpoint(model, f\"model_{unique_id}.pth\")\n",
    "            best_training_loss = avg_train_loss\n",
    "            best_validation_loss = avg_val_loss\n",
    "\n",
    "    # record training, validationg losses, weight updates, and the result model path\n",
    "    history_dict['best_epoch'] = best_epoch\n",
    "    history_dict['best_val'] = best_validation_loss\n",
    "    history_dict['best_train'] = best_training_loss\n",
    "    history_dict['training_loss'] = train_losses\n",
    "    history_dict['validation_loss'] = val_losses\n",
    "\n",
    "    for history in history_dict:\n",
    "        print(f'{history}: {history_dict[history]}\\n')\n",
    "\n",
    "    log_data_to_csv(history_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d04a9b-00be-4cc5-bf44-1e5e1a95f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_architecture[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000d021-0d87-4850-8aae-971ce7876046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

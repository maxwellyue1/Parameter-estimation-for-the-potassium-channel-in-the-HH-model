{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from dataset_reader import Traces_Dataset\n",
    "from mlp_model import MLP\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "target_features = 7\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 50\n",
    "\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 300\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 321\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, target_features))\n",
    "    # layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    dataset = Traces_Dataset('dataset_test.csv')\n",
    "    dataset.split_dataset(0.95, 0.05, 0)\n",
    "    dataset.clean_features()\n",
    "    dataset.find_mean_std()\n",
    "    dataset.normalize()\n",
    "    print(dataset.inputs.shape)\n",
    "\n",
    "    # initialize train, val, test set\n",
    "    X_train = dataset[dataset.train_set.indices][0]\n",
    "    Y_train = dataset[dataset.train_set.indices][1]\n",
    "\n",
    "    X_val = dataset[dataset.val_set.indices][0]\n",
    "    Y_val = dataset[dataset.val_set.indices][1]\n",
    "\n",
    "    X_test = dataset[dataset.test_set.indices][0]\n",
    "    Y_test = dataset[dataset.test_set.indices][1]\n",
    "\n",
    "    # initialize dataloader \n",
    "    train_dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val, Y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_dataset()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (train_inputs, train_targets) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            # data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "            train_inputs, train_targets = train_inputs.to(DEVICE), train_targets.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_outputs = model(train_inputs)\n",
    "            loss = nn.MSELoss()(train_outputs, train_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (val_inputs, val_targets) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                # data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                val_inputs, val_targets = val_inputs.to(DEVICE), val_targets.to(DEVICE)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                # Get the index of the max log-probability.\n",
    "                val_loss = nn.MSELoss()(val_outputs, val_targets)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "            # Average validation loss for the epoch\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:24,808] A new study created in memory with name: no-name-e7f0ea8c-a15c-4c81-a4bc-933af8106038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-03-27 00:16:25,151] Trial 0 failed with parameters: {'n_layers': 2, 'n_units_l0': 106, 'dropout_l0': 0.4176551516861762, 'n_units_l1': 13, 'dropout_l1': 0.26076988483133545, 'optimizer': 'SGD', 'lr': 0.004338569032270813} because of the following error: The value nan is not acceptable.\n",
      "[W 2024-03-27 00:16:25,151] Trial 0 failed with value nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:25,409] Trial 1 finished with value: 3230.15283203125 and parameters: {'n_layers': 2, 'n_units_l0': 26, 'dropout_l0': 0.29452755895454896, 'n_units_l1': 33, 'dropout_l1': 0.4141746209705277, 'optimizer': 'SGD', 'lr': 1.170491290848602e-05}. Best is trial 1 with value: 3230.15283203125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:25,697] Trial 2 finished with value: 3.9118971236489615e+27 and parameters: {'n_layers': 3, 'n_units_l0': 21, 'dropout_l0': 0.48764535493792166, 'n_units_l1': 36, 'dropout_l1': 0.42239039750498464, 'n_units_l2': 49, 'dropout_l2': 0.36077153024294883, 'optimizer': 'SGD', 'lr': 0.08632104909405758}. Best is trial 1 with value: 3230.15283203125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:26,013] Trial 3 finished with value: 176.05076599121094 and parameters: {'n_layers': 3, 'n_units_l0': 39, 'dropout_l0': 0.43911836190232006, 'n_units_l1': 38, 'dropout_l1': 0.34206698459115487, 'n_units_l2': 67, 'dropout_l2': 0.49042462733843706, 'optimizer': 'SGD', 'lr': 0.0003965631338280223}. Best is trial 3 with value: 176.05076599121094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:26,286] Trial 4 finished with value: 3169.2138671875 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_l0': 0.45627810147068537, 'optimizer': 'RMSprop', 'lr': 2.7227791457024097e-05}. Best is trial 3 with value: 176.05076599121094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:26,601] Trial 5 finished with value: 313.1454162597656 and parameters: {'n_layers': 1, 'n_units_l0': 48, 'dropout_l0': 0.43885862197167647, 'optimizer': 'Adam', 'lr': 0.0008920531155704004}. Best is trial 3 with value: 176.05076599121094.\n",
      "[I 2024-03-27 00:16:26,649] Trial 6 pruned. \n",
      "[I 2024-03-27 00:16:26,693] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:27,272] Trial 8 finished with value: 85.91513061523438 and parameters: {'n_layers': 3, 'n_units_l0': 114, 'dropout_l0': 0.24355783711724283, 'n_units_l1': 127, 'dropout_l1': 0.44042116717550217, 'n_units_l2': 21, 'dropout_l2': 0.23498219133243806, 'optimizer': 'Adam', 'lr': 0.005553331557829604}. Best is trial 8 with value: 85.91513061523438.\n",
      "/Users/maxwellyue/anaconda3/lib/python3.10/site-packages/optuna/pruners/_percentile.py:20: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmin(values)\n",
      "[I 2024-03-27 00:16:27,316] Trial 9 pruned. \n",
      "[I 2024-03-27 00:16:27,433] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:27,919] Trial 11 finished with value: 75.36658477783203 and parameters: {'n_layers': 2, 'n_units_l0': 77, 'dropout_l0': 0.20090088195157038, 'n_units_l1': 127, 'dropout_l1': 0.497224166313486, 'optimizer': 'Adam', 'lr': 0.005625701249089737}. Best is trial 11 with value: 75.36658477783203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:28,362] Trial 12 finished with value: 68.23986053466797 and parameters: {'n_layers': 2, 'n_units_l0': 82, 'dropout_l0': 0.2034032430966227, 'n_units_l1': 126, 'dropout_l1': 0.4948500916054156, 'optimizer': 'Adam', 'lr': 0.007689302990693475}. Best is trial 12 with value: 68.23986053466797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:28,778] Trial 13 finished with value: 92.07085418701172 and parameters: {'n_layers': 2, 'n_units_l0': 74, 'dropout_l0': 0.20231049515957641, 'n_units_l1': 86, 'dropout_l1': 0.4982321563127643, 'optimizer': 'Adam', 'lr': 0.013147578737570146}. Best is trial 12 with value: 68.23986053466797.\n",
      "[I 2024-03-27 00:16:28,832] Trial 14 pruned. \n",
      "[I 2024-03-27 00:16:28,936] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:29,335] Trial 16 finished with value: 85.67589569091797 and parameters: {'n_layers': 2, 'n_units_l0': 61, 'dropout_l0': 0.34647738617466867, 'n_units_l1': 101, 'dropout_l1': 0.45859135694848435, 'optimizer': 'Adam', 'lr': 0.003851702549424317}. Best is trial 12 with value: 68.23986053466797.\n",
      "[I 2024-03-27 00:16:29,483] Trial 17 pruned. \n",
      "[I 2024-03-27 00:16:29,538] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 00:16:29,872] Trial 19 finished with value: 90.40322875976562 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_l0': 0.23788490246006797, 'n_units_l1': 110, 'dropout_l1': 0.37361011198862604, 'optimizer': 'RMSprop', 'lr': 0.00548727897266424}. Best is trial 12 with value: 68.23986053466797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  20\n",
      "  Number of pruned trials:  8\n",
      "  Number of complete trials:  11\n",
      "Best trial:\n",
      "  Value:  68.23986053466797\n",
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 82\n",
      "    dropout_l0: 0.2034032430966227\n",
      "    n_units_l1: 126\n",
      "    dropout_l1: 0.4948500916054156\n",
      "    optimizer: Adam\n",
      "    lr: 0.007689302990693475\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from dataset_reader import Traces_Dataset\n",
    "from mlp_model import MLP\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "target_features = 7\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 50\n",
    "\n",
    "N_TRAIN_EXAMPLES = 10 * 300\n",
    "N_VALID_EXAMPLES = 10 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 321\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 16, 321)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, target_features))\n",
    "    # layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(trial):\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256, 512, 1024])\n",
    "    \n",
    "    dataset = Traces_Dataset('dataset_test.csv')\n",
    "    dataset.split_dataset(0.95, 0.05, 0)\n",
    "    dataset.clean_features()\n",
    "    dataset.find_mean_std()\n",
    "    dataset.normalize()\n",
    "    print(dataset.inputs.shape)\n",
    "\n",
    "    # initialize train, val, test set\n",
    "    X_train = dataset[dataset.train_set.indices][0]\n",
    "    Y_train = dataset[dataset.train_set.indices][1]\n",
    "\n",
    "    X_val = dataset[dataset.val_set.indices][0]\n",
    "    Y_val = dataset[dataset.val_set.indices][1]\n",
    "\n",
    "    X_test = dataset[dataset.test_set.indices][0]\n",
    "    Y_test = dataset[dataset.test_set.indices][1]\n",
    "\n",
    "    # initialize dataloader \n",
    "    train_dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val, Y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_dataset(trial)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (train_inputs, train_targets) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * 10 >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            # data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "            train_inputs, train_targets = train_inputs.to(DEVICE), train_targets.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_outputs = model(train_inputs)\n",
    "            loss = nn.MSELoss()(train_outputs, train_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (val_inputs, val_targets) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * 10 >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                # data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                val_inputs, val_targets = val_inputs.to(DEVICE), val_targets.to(DEVICE)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                # Get the index of the max log-probability.\n",
    "                val_loss = nn.MSELoss()(val_outputs, val_targets)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "            # Average validation loss for the epoch\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:49,481] A new study created in memory with name: no-name-527fdee5-c8a9-490d-97aa-79f1fcf1484b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:49,780] Trial 0 finished with value: 2855.56884765625 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.22733226711445575, 'optimizer': 'RMSprop', 'lr': 0.00010700405515314282, 'batch_size': 512}. Best is trial 0 with value: 2855.56884765625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:50,045] Trial 1 finished with value: 148.9717559814453 and parameters: {'n_layers': 2, 'n_units_l0': 43, 'dropout_l0': 0.4990525363955867, 'n_units_l1': 22, 'dropout_l1': 0.2606691756103567, 'optimizer': 'Adam', 'lr': 0.04561459107659196, 'batch_size': 256}. Best is trial 1 with value: 148.9717559814453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:51,154] Trial 2 finished with value: 349.80023193359375 and parameters: {'n_layers': 4, 'n_units_l0': 129, 'dropout_l0': 0.48551120660818026, 'n_units_l1': 306, 'dropout_l1': 0.39435393372484245, 'n_units_l2': 304, 'dropout_l2': 0.2708554250443419, 'n_units_l3': 234, 'dropout_l3': 0.43256801047677307, 'optimizer': 'Adam', 'lr': 3.356047461620424e-05, 'batch_size': 128}. Best is trial 1 with value: 148.9717559814453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:51,426] Trial 3 finished with value: 3223.8056640625 and parameters: {'n_layers': 2, 'n_units_l0': 93, 'dropout_l0': 0.3477335924067406, 'n_units_l1': 60, 'dropout_l1': 0.2509113497490308, 'optimizer': 'RMSprop', 'lr': 1.3103820133459395e-05, 'batch_size': 512}. Best is trial 1 with value: 148.9717559814453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:55,178] Trial 4 finished with value: 274.44824600219727 and parameters: {'n_layers': 5, 'n_units_l0': 304, 'dropout_l0': 0.37397797090505525, 'n_units_l1': 36, 'dropout_l1': 0.4398636523504552, 'n_units_l2': 92, 'dropout_l2': 0.29552974740846266, 'n_units_l3': 86, 'dropout_l3': 0.2984455323725679, 'n_units_l4': 273, 'dropout_l4': 0.2163777070624155, 'optimizer': 'Adam', 'lr': 5.268220843306462e-05, 'batch_size': 16}. Best is trial 1 with value: 148.9717559814453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:55,597] Trial 5 finished with value: 256.9565734863281 and parameters: {'n_layers': 3, 'n_units_l0': 172, 'dropout_l0': 0.31729669608876754, 'n_units_l1': 178, 'dropout_l1': 0.2793585828718232, 'n_units_l2': 135, 'dropout_l2': 0.41313037454744045, 'optimizer': 'RMSprop', 'lr': 0.0003776858268757089, 'batch_size': 1024}. Best is trial 1 with value: 148.9717559814453.\n",
      "[I 2024-03-27 01:37:55,688] Trial 6 pruned. \n",
      "[I 2024-03-27 01:37:55,733] Trial 7 pruned. \n",
      "[I 2024-03-27 01:37:55,832] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:56,536] Trial 9 finished with value: 96.78843688964844 and parameters: {'n_layers': 3, 'n_units_l0': 105, 'dropout_l0': 0.2616313052618471, 'n_units_l1': 271, 'dropout_l1': 0.22890079083443746, 'n_units_l2': 169, 'dropout_l2': 0.448719831664334, 'optimizer': 'Adam', 'lr': 0.0013844500401859064, 'batch_size': 256}. Best is trial 9 with value: 96.78843688964844.\n",
      "/Users/maxwellyue/anaconda3/lib/python3.10/site-packages/optuna/pruners/_percentile.py:20: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmin(values)\n",
      "[I 2024-03-27 01:37:56,608] Trial 10 pruned. \n",
      "[I 2024-03-27 01:37:56,748] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:56,804] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:57,290] Trial 13 finished with value: 89.01972198486328 and parameters: {'n_layers': 3, 'n_units_l0': 52, 'dropout_l0': 0.2806062747331935, 'n_units_l1': 120, 'dropout_l1': 0.33868845274871306, 'n_units_l2': 249, 'dropout_l2': 0.20595601499396263, 'optimizer': 'Adam', 'lr': 0.013319859294656915, 'batch_size': 256}. Best is trial 13 with value: 89.01972198486328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:57,990] Trial 14 finished with value: 80.54651641845703 and parameters: {'n_layers': 4, 'n_units_l0': 171, 'dropout_l0': 0.27654455496906005, 'n_units_l1': 122, 'dropout_l1': 0.3329525784217172, 'n_units_l2': 253, 'dropout_l2': 0.49701927558438475, 'n_units_l3': 163, 'dropout_l3': 0.49887652034845, 'optimizer': 'Adam', 'lr': 0.00924472497677181, 'batch_size': 256}. Best is trial 14 with value: 80.54651641845703.\n",
      "[I 2024-03-27 01:37:58,085] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:37:59,818] Trial 16 pruned. \n",
      "/Users/maxwellyue/anaconda3/lib/python3.10/site-packages/optuna/pruners/_percentile.py:20: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmin(values)\n",
      "[I 2024-03-27 01:37:59,894] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n",
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:38:03,378] Trial 18 finished with value: 49.37183094024658 and parameters: {'n_layers': 4, 'n_units_l0': 161, 'dropout_l0': 0.20600770445362854, 'n_units_l1': 150, 'dropout_l1': 0.30167377439845716, 'n_units_l2': 267, 'dropout_l2': 0.49784224537991045, 'n_units_l3': 110, 'dropout_l3': 0.2690332022158084, 'optimizer': 'Adam', 'lr': 0.0006726580394291194, 'batch_size': 16}. Best is trial 18 with value: 49.37183094024658.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 321])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 01:38:07,775] Trial 19 finished with value: 45.33682465553284 and parameters: {'n_layers': 4, 'n_units_l0': 174, 'dropout_l0': 0.20698929462045085, 'n_units_l1': 225, 'dropout_l1': 0.30723814508389546, 'n_units_l2': 321, 'dropout_l2': 0.4999956412579912, 'n_units_l3': 107, 'dropout_l3': 0.2550368762103258, 'optimizer': 'Adam', 'lr': 0.0003417690685853737, 'batch_size': 16}. Best is trial 19 with value: 45.33682465553284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  20\n",
      "  Number of pruned trials:  9\n",
      "  Number of complete trials:  11\n",
      "Best trial:\n",
      "  Value:  45.33682465553284\n",
      "  Params: \n",
      "    n_layers: 4\n",
      "    n_units_l0: 174\n",
      "    dropout_l0: 0.20698929462045085\n",
      "    n_units_l1: 225\n",
      "    dropout_l1: 0.30723814508389546\n",
      "    n_units_l2: 321\n",
      "    dropout_l2: 0.4999956412579912\n",
      "    n_units_l3: 107\n",
      "    dropout_l3: 0.2550368762103258\n",
      "    optimizer: Adam\n",
      "    lr: 0.0003417690685853737\n",
      "    batch_size: 16\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 0.5167787332586548,\n",
       " 'n_layers': 0.16080507562249335,\n",
       " 'optimizer': 0.15665348579823324,\n",
       " 'dropout_l0': 0.06870345193655863,\n",
       " 'lr': 0.06637936426822885,\n",
       " 'n_units_l0': 0.0306798891158311}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
